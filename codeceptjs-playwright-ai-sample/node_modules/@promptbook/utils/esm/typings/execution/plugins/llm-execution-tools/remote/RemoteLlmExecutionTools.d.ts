import { Prompt } from '../../../../types/Prompt';
import { LlmExecutionTools } from '../../../LlmExecutionTools';
import { PromptChatResult, PromptCompletionResult } from '../../../PromptResult';
import { RemoteLlmExecutionToolsOptions } from './RemoteLlmExecutionToolsOptions';
/**
 * Remote server is a proxy server that uses its execution tools internally and exposes the executor interface externally.
 *
 * You can simply use `RemoteExecutionTools` on client-side javascript and connect to your remote server.
 * This is useful to make all logic on browser side but not expose your API keys or no need to use customer's GPU.
 *
 * @see https://github.com/webgptorg/promptbook#remote-server
 */
export declare class RemoteLlmExecutionTools implements LlmExecutionTools {
    private readonly options;
    constructor(options: RemoteLlmExecutionToolsOptions);
    /**
     * Creates a connection to the remote proxy server.
     */
    private makeConnection;
    /**
     * Calls remote proxy server to use a chat model.
     */
    gptChat(prompt: Prompt): Promise<PromptChatResult>;
    /**
     * Calls remote proxy server to use a completion model.
     */
    gptComplete(prompt: Prompt): Promise<PromptCompletionResult>;
    /**
     * Calls remote proxy server to use both completion or chat model.
     */
    private gptCommon;
}
/**
 * TODO: [üçì][‚ôê] Allow to list compatible models with each variant
 * TODO: [ü§π‚Äç‚ôÇÔ∏è] RemoteLlmExecutionTools should extend Destroyable and implement IDestroyable
 */
